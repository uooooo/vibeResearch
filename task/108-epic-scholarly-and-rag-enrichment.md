# 108: Scholarly Search & RAG Enrichment

- Status: Planned
- Owner: TBD
- Goal: Provide optional retrieval context (arXiv/Semantic Scholar + pgvector) to ground LLM outputs and collect citations.

## Milestones
1) Scholarly Clients: arXiv + Semantic Scholar minimal query wrappers + normalizers
2) RAG Basics: chunking, embedding, store in `chunks` with pgvector; keyword query â†’ vector search
3) Tooling: `rag.search` tool to feed snippets into prompts; track provenance
4) Citations: map retrieved metadata to CSL and include in plan export

## Acceptance Criteria
- `rag.search` returns top-k snippets with titles/urls
- Plan draft can include citations when RAG used
- Export includes References and CSL items

## Breakdown (Stories)
- [ ] API Clients: implement `lib/scholarly/{arxiv,semantic-scholar}.ts` with query, normalize to common shape
- [ ] Rate Limits: add basic backoff/retry and per-run cap; cache recent results to avoid duplicate calls
- [ ] Embeddings: choose model (e.g., `text-embedding-3-small`), add ingestion util with chunker
- [ ] Storage: write chunks with embeddings to `chunks` (pgvector) and link to source `documents`
- [ ] Search: implement `rag.search(query)` combining keyword + vector search; return snippets + provenance
- [ ] Prompt Wiring: add optional context block to LLM prompts; include citation markers
- [ ] Export: map provenance to CSL JSON and include in Markdown export
- [ ] Context7: consult API docs for arXiv/Semantic Scholar when implementing

## Risks / Mitigations
- API instability: normalize fields; keep minimal required shape; cache
- Irrelevant context: use rerank or small k; prompt guards to only cite used snippets
